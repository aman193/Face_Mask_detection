{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fd2baea",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "674ec21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c590b6e2",
   "metadata": {},
   "source": [
    "### Initializing parameters for training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2bb5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "EPOCHS = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35847e",
   "metadata": {},
   "source": [
    "### Directory of dataset and category of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "267bc484",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"dataset\"\n",
    "categories = [\"MASK\", \"NO_MASK\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0da7e8e",
   "metadata": {},
   "source": [
    "### Load images from the directory and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf2de0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "for category in categories:\n",
    "    path = os.path.join(directory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "        \n",
    "        data.append(image)\n",
    "        labels.append(category)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04879d1",
   "metadata": {},
   "source": [
    "### one hot encoding for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53703d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ab6ff7",
   "metadata": {},
   "source": [
    "### Converting dada and labels into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512b1569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\")\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c3b457",
   "metadata": {},
   "source": [
    "### Split data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "db6676d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(data, labels, test_size=0.20, stratify=labels, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5426e42",
   "metadata": {},
   "source": [
    "### Using image data generator to generate more training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d019ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a347e16",
   "metadata": {},
   "source": [
    "### Load MobileNet model (head fc layers set are left off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bf580d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n"
     ]
    }
   ],
   "source": [
    "baseModel = MobileNetV2(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a3fb84",
   "metadata": {},
   "source": [
    "### construct the head model and place on the top of the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e79c8bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(2, activation=\"softmax\")(headModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33d8106",
   "metadata": {},
   "source": [
    "### New Model for our purpose (place head on top of base model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02ba5021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=baseModel.input, outputs=headModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633b7a81",
   "metadata": {},
   "source": [
    "### Freez the layers in the base model (should not update in first training process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e606293",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseModel.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a3e57",
   "metadata": {},
   "source": [
    "### Compliling our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a939f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] compiling model...\n",
      "[info] compiled successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"[info] compiling model...\")\n",
    "\n",
    "opt = Adam(learning_rate=learning_rate, decay = learning_rate/EPOCHS)\n",
    "\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer=opt, metrics=[\"Accuracy\"])\n",
    "\n",
    "print(\"[info] compiled successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa35652",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3c14a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] training head...\n",
      "Epoch 1/20\n",
      "48/48 [==============================] - 56s 899ms/step - loss: 0.3455 - accuracy: 0.0000e+00 - val_loss: 0.0775 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "48/48 [==============================] - 27s 547ms/step - loss: 0.1006 - accuracy: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "48/48 [==============================] - 28s 587ms/step - loss: 0.0617 - accuracy: 0.0052 - val_loss: 0.0163 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "48/48 [==============================] - 27s 556ms/step - loss: 0.0422 - accuracy: 0.0187 - val_loss: 0.0111 - val_accuracy: 0.0038\n",
      "Epoch 5/20\n",
      "48/48 [==============================] - 26s 550ms/step - loss: 0.0332 - accuracy: 0.0389 - val_loss: 0.0080 - val_accuracy: 0.0179\n",
      "Epoch 6/20\n",
      "48/48 [==============================] - 27s 555ms/step - loss: 0.0261 - accuracy: 0.0628 - val_loss: 0.0074 - val_accuracy: 0.0487\n",
      "Epoch 7/20\n",
      "48/48 [==============================] - 27s 566ms/step - loss: 0.0272 - accuracy: 0.0890 - val_loss: 0.0059 - val_accuracy: 0.0718\n",
      "Epoch 8/20\n",
      "48/48 [==============================] - 27s 563ms/step - loss: 0.0157 - accuracy: 0.0965 - val_loss: 0.0049 - val_accuracy: 0.1064\n",
      "Epoch 9/20\n",
      "48/48 [==============================] - 27s 550ms/step - loss: 0.0142 - accuracy: 0.1276 - val_loss: 0.0046 - val_accuracy: 0.1372\n",
      "Epoch 10/20\n",
      "48/48 [==============================] - 28s 571ms/step - loss: 0.0142 - accuracy: 0.1502 - val_loss: 0.0066 - val_accuracy: 0.1744\n",
      "Epoch 11/20\n",
      "48/48 [==============================] - 27s 554ms/step - loss: 0.0150 - accuracy: 0.1662 - val_loss: 0.0045 - val_accuracy: 0.1885\n",
      "Epoch 12/20\n",
      "48/48 [==============================] - 27s 559ms/step - loss: 0.0091 - accuracy: 0.1810 - val_loss: 0.0030 - val_accuracy: 0.2218\n",
      "Epoch 13/20\n",
      "48/48 [==============================] - 27s 551ms/step - loss: 0.0083 - accuracy: 0.2026 - val_loss: 0.0034 - val_accuracy: 0.2423\n",
      "Epoch 14/20\n",
      "48/48 [==============================] - 27s 561ms/step - loss: 0.0076 - accuracy: 0.2124 - val_loss: 0.0031 - val_accuracy: 0.2679\n",
      "Epoch 15/20\n",
      "48/48 [==============================] - 27s 570ms/step - loss: 0.0057 - accuracy: 0.2393 - val_loss: 0.0031 - val_accuracy: 0.2936\n",
      "Epoch 16/20\n",
      "48/48 [==============================] - 28s 588ms/step - loss: 0.0073 - accuracy: 0.2438 - val_loss: 0.0031 - val_accuracy: 0.3141\n",
      "Epoch 17/20\n",
      "48/48 [==============================] - 27s 564ms/step - loss: 0.0102 - accuracy: 0.2667 - val_loss: 0.0049 - val_accuracy: 0.2936\n",
      "Epoch 18/20\n",
      "48/48 [==============================] - 28s 578ms/step - loss: 0.0077 - accuracy: 0.2497 - val_loss: 0.0029 - val_accuracy: 0.3346\n",
      "Epoch 19/20\n",
      "48/48 [==============================] - 27s 556ms/step - loss: 0.0066 - accuracy: 0.2644 - val_loss: 0.0038 - val_accuracy: 0.3282\n",
      "Epoch 20/20\n",
      "48/48 [==============================] - 27s 570ms/step - loss: 0.0085 - accuracy: 0.2745 - val_loss: 0.0049 - val_accuracy: 0.3179\n",
      "[info] trained successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"[info] training head...\")\n",
    "\n",
    "H = model.fit(aug.flow(trainX, trainY, batch_size=batch_size),\n",
    "             steps_per_epoch=len(trainX)//batch_size,\n",
    "             validation_data=(testX, testY),\n",
    "             validation_steps=len(testX)//batch_size,\n",
    "             epochs=EPOCHS\n",
    "             )\n",
    "\n",
    "print(\"[info] trained successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb0d88",
   "metadata": {},
   "source": [
    "### Prediction on testing set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6e5fb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] evaluating network...\n",
      "[info] prections ids ready to evalute ...\n"
     ]
    }
   ],
   "source": [
    "print(\"[info] evaluating network...\")\n",
    "predIds = model.predict(testX, batch_size=batch_size)\n",
    "print(\"[info] prections ids ready to evalute ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f18500",
   "metadata": {},
   "source": [
    "### Compare True labels with predicted labels (max probability of predicted labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4db176b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predIds = np.argmax(predIds, axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645106d",
   "metadata": {},
   "source": [
    "### Show classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15697d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MASK       0.99      1.00      1.00       190\n",
      "     NO_MASK       1.00      0.99      1.00       200\n",
      "\n",
      "    accuracy                           1.00       390\n",
      "   macro avg       1.00      1.00      1.00       390\n",
      "weighted avg       1.00      1.00      1.00       390\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(testY.argmax(axis=1), predIds, target_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b71a0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
